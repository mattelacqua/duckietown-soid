# Set the log level of the application
[LOGGING]
# Verbosity
VERBOSE = False

# Randomization settings
[RANDOMIZATION]
# Seed
SEED = 1
# enable domain randomization
DOMAIN_RAND = False 
# enable dynamics randomization
DYNAMICS_RAND = False 
# Unsure
DISTORTION = False 
CAMERA_RAND = False

# Simulator Settings
[SETUP]
# Environment Name
ENV = Duckietown-reinforcement-learning-v0 
# Map Name
MAP = reinforcement_learning.yaml
# Draw road tile curves 
DRAW_CURVE = True
# Draw bounding box of agent
DRAW_BBOX = True 
# Number of frames to skip
FRAME_SKIP = 1 
# Camera modes: human, top_down, free_cam, rgb_array
CAM_MODE = top_down  


[AGENTS]
# Number of agents 
NUM_RANDOM_AGENTS = 3
# Max agents
MAX_AGENTS = 8
# Minimum distance before collision detection
SAFETY_FACTOR = 1.0

[LEARNING]
# Save the models
SAVE_MODELS = TRUE
# Save directory 
MODEL_DIR = learning/reinforcement/q-learning/models/
# Test model path
TEST_MODEL_PATH = learning/reinforcement/q-learning/models/defensive/episodebatch_999
# Learning Rate
ALPHA = 0.1
# Learning Rate Decay
LEARNING_RATE_DECAY = 0.5
# Discount Factor
GAMMA = 0.8
# E-Greedy Action Choice
EPSILON = 0.35
# Number of episodes
NUM_EPISODES = 1000
# number of testing iterations
NUM_ITERATIONS = 100
# Model number we want to test
MODEL_NUM = 0
# Reward Profile: 0 = Pathological 1= Reckless 2=Defensive
REWARD_PROFILE = 2
# Render the learning
RENDER_STEPS = 4

